{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4432ae0f",
   "metadata": {},
   "source": [
    "# Intro to JAX "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afce8b",
   "metadata": {},
   "source": [
    "Author: Nathaniel Starkman (MIT, starkman@mit.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829e238",
   "metadata": {},
   "source": [
    "What JAX brings to the table:\n",
    "\n",
    "1. Python\n",
    "2. Familiar (numpy) API\n",
    "3. JIT = Speed\n",
    "4. GPU support\n",
    "5. Sharding\n",
    "6. Auto-differentiation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec870b14",
   "metadata": {},
   "source": [
    "For science we often want to work with float64, not float32.\n",
    "We can set this permanently with an environment variable (see JAX docs)\n",
    "or with a configuration at import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4394f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d2ef20",
   "metadata": {},
   "source": [
    "We are going to be explicit about dtypes and shapes.\n",
    "For this we will use the very popular `jaxtyping` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd0bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float, Array, Shaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9be38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dd2e895",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6224fe7",
   "metadata": {},
   "source": [
    "(adapted from [Quickstart](https://jax.readthedocs.io/en/latest/quickstart.html) and [Sharp Bits](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#jax-the-sharp-bits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345be57f",
   "metadata": {},
   "source": [
    "Mostly you need to replace `numpy` with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58e728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a6c77",
   "metadata": {},
   "source": [
    "Now you can write familiar functions with JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc6846f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(55., dtype=float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_of_squares(\n",
    "    x: Shaped[Array, \"N\"], /, *, axis: int | None = None,\n",
    ") -> Shaped[Array, \"1\"]:\n",
    "    return jnp.sum(jnp.square(x), axis=axis)\n",
    "\n",
    "sum_of_squares(jnp.array([1., 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481965a",
   "metadata": {},
   "source": [
    "There are well-known \"Sharp Bits\" to JAX.\n",
    "Let's highlight one here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02cbfae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX arrays are immutable and do not support in-place item assignment. Instead of x[idx] = y, use x = x.at[idx].set(y) or another .at[] method: https://docs.jax.dev/en/latest/_autosummary/jax.numpy.ndarray.at.html\n"
     ]
    }
   ],
   "source": [
    "jax_array = jnp.zeros((3,3), dtype=jnp.float32)\n",
    "\n",
    "# In place update of JAX's array will yield an error!\n",
    "try:\n",
    "    jax_array[1, :] = 1.0\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded9ea5",
   "metadata": {},
   "source": [
    "JAX arrays are immutable!\n",
    "\n",
    "From many perspectives this is actually really nice (it's safer for operation tracing and harder to make in-place update mistakes).\n",
    "However 2 points against it are:\n",
    "\n",
    "1. As a NumPy user I'm not used to this!\n",
    "2. Aren't out-of-place updates slower?\n",
    "\n",
    "Yes, the first point is true.\n",
    "The second point / question is more complex. It can be slower the first time the program runs, but if the operation is within a JIT then the out-of-place updates are fused into highly-optimized in-place updates that are actually faster!\n",
    "\n",
    "So if we build familiarity with JAX's out-of-place updates, then it's kind of better in every way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f1c0868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new array:\n",
      " [[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "new_array = jax_array.at[1, :].set(1.0)\n",
    "print(\"new array:\\n\", new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e34b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eb48e90",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45df81eb",
   "metadata": {},
   "source": [
    "Adapted from [automatic-vectorization](https://jax.readthedocs.io/en/latest/automatic-vectorization.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e10507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(x: Float[Array, \"N\"], w: Float[Array, \"3\"]) -> Float[Array, \"N-2\"]:\n",
    "  return jnp.array([jnp.dot(x[i-1:i+2], w)\n",
    "                    for i in range(1, len(x)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526fc589",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.arange(6, dtype=float)\n",
    "w = jnp.array([2., 3., 4.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f053f1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([11., 20., 29., 38.], dtype=float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c90b6658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = jnp.stack([x, x])\n",
    "ws = jnp.stack([w, w])\n",
    "\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8209b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([], shape=(0,), dtype=float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve(xs, ws)  # Not what we want!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214f1c2f",
   "metadata": {},
   "source": [
    "How do we vectorize operations in JAX?\n",
    "\n",
    "Some operations are already vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e248f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.        ,  0.54030231, -0.41614684, -0.9899925 , -0.65364362,\n",
       "         0.28366219],\n",
       "       [ 1.        ,  0.54030231, -0.41614684, -0.9899925 , -0.65364362,\n",
       "         0.28366219]], dtype=float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.cos(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa972c",
   "metadata": {},
   "source": [
    "But for those that aren't, there's..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fac5294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmap_convolve = jax.vmap(convolve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fdfba15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[11., 20., 29., 38.],\n",
       "       [11., 20., 29., 38.]], dtype=float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmap_convolve(xs, ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d57f1a",
   "metadata": {},
   "source": [
    "The only problem is that `vmap` only vectorizes over\n",
    "pre-specified axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83dbf01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([], shape=(1, 0), dtype=float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmap_convolve(xs[None], ws[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aac852",
   "metadata": {},
   "source": [
    "That's why there's `jax.numpy.vectorize`. This is like `vmap` but requires less *a priori* knowledge of array shapes.\n",
    "\n",
    "JAX doesn't really advertise  `jax.numpy.vectorize` as a `vmap` alternative, but it's very convenient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37f4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_convolve = jnp.vectorize(convolve, signature=\"(n),(w)->(m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2ff0e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[11., 20., 29., 38.],\n",
       "        [11., 20., 29., 38.]]], dtype=float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_convolve(xs[None], ws[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67838c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef7a7d80",
   "metadata": {},
   "source": [
    "## JIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a297b169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 Î¼s Â± 1.93 Î¼s per loop (mean Â± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit convolve(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "759deec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_convolve = jax.jit(convolve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94b8349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.47 Î¼s Â± 55.6 ns per loop (mean Â± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "jit_convolve(x, w)  # trigger jit\n",
    "\n",
    "%timeit jit_convolve(x, w).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98855b74",
   "metadata": {},
   "source": [
    "70x speedup! ðŸ˜±\n",
    "\n",
    "And that's on a CPU. GPU is even better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8897c",
   "metadata": {},
   "source": [
    "What about the vectorized version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f9e2937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322 Î¼s Â± 8.86 Î¼s per loop (mean Â± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit vec_convolve(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd749a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_vec_convolve = jax.jit(vec_convolve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70570b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.32 Î¼s Â± 33.9 ns per loop (mean Â± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "jit_vec_convolve(x, w)  # trigger jit\n",
    "\n",
    "%timeit jit_vec_convolve(x, w).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e037216",
   "metadata": {},
   "source": [
    "ðŸ¥³ we get highly general vectorization basically for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cbdc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f004926",
   "metadata": {},
   "source": [
    "## Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbef9479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function jax._src.api.grad(fun: 'Callable', argnums: 'int | Sequence[int]' = 0, has_aux: 'bool' = False, holomorphic: 'bool' = False, allow_int: 'bool' = False, reduce_axes: 'Sequence[AxisName]' = ()) -> 'Callable'>,\n",
       " <function jax._src.api.jacfwd(fun: 'Callable', argnums: 'int | Sequence[int]' = 0, has_aux: 'bool' = False, holomorphic: 'bool' = False) -> 'Callable'>,\n",
       " <function jax._src.api.jacrev(fun: 'Callable', argnums: 'int | Sequence[int]' = 0, has_aux: 'bool' = False, holomorphic: 'bool' = False, allow_int: 'bool' = False) -> 'Callable'>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad, jax.jacfwd, jax.jacrev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3cdae",
   "metadata": {},
   "source": [
    "Jacobians are easy. The output is a matrix of the derivatives of the outputs versus the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74a8e230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[2., 3., 4., 0., 0., 0.],\n",
       "       [0., 2., 3., 4., 0., 0.],\n",
       "       [0., 0., 2., 3., 4., 0.],\n",
       "       [0., 0., 0., 2., 3., 4.]], dtype=float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac_fn = jax.jacobian(convolve)\n",
    "jac_fn(x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e17bb",
   "metadata": {},
   "source": [
    "Gradients can be a little more tricky since they must be scalar-valued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "001e08cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient only defined for scalar-output functions. Output had shape: (4,).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    jax.grad(convolve)(x, w)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a404a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[2., 3., 4.],\n",
       "       [2., 3., 4.],\n",
       "       [2., 3., 4.],\n",
       "       [2., 3., 4.]], dtype=float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is one not-great way\n",
    "func = lambda x, w: jnp.asarray([jax.grad(\n",
    "    lambda x, w: convolve(x, w)[0]  # scalar output\n",
    ")(x[i:i+3], w) for i in range(len(x) - 2)\n",
    "])\n",
    "func(x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74459f88",
   "metadata": {},
   "source": [
    "Note that this hack to produce scalar output basically just produced the diagonal of the `jacobian` calculation.\n",
    "`grad` is intended for scalar functions, which this example was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee3e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3c75b25",
   "metadata": {},
   "source": [
    "## PyTrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f37070",
   "metadata": {},
   "source": [
    "Adapted from https://docs.kidger.site/equinox/all-of-equinox/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e091f403",
   "metadata": {},
   "source": [
    "`PyTrees` are what `JAX` calls nested collections.\n",
    "`JAX` has built-in support for tuples, lists, and dicts, but can also support any custom type, if properly registered.\n",
    "\n",
    "`PyTrees` can be built out of pretty much anything: JAX/NumPy arrays, floats, functions, etc.\n",
    "\n",
    "Many JAX operations will accept either:\n",
    "\n",
    "- arbitrary PyTrees;\n",
    "- PyTrees with just JAX/NumPy arrays as the leaves;\n",
    "- PyTrees without any JAX/NumPy arrays as the leaves.\n",
    "\n",
    "Functions in `jax.numpy` just need to be `tree_map`ed over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4855365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': Array([ 1.000000e+00,  6.123234e-17, -1.000000e+00], dtype=float64),\n",
       " 'b': [Array([0.70710678, 0.5       ], dtype=float64),\n",
       "  Array([0.8660254], dtype=float64)],\n",
       " 'c': (Array([1.], dtype=float64), Array([-1.], dtype=float64))}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example pytree\n",
    "pytree = {\n",
    "    'a': jnp.array([0.0, jnp.pi / 2, jnp.pi]),\n",
    "    'b': [jnp.array([jnp.pi / 4, jnp.pi / 3]), jnp.array([jnp.pi / 6])],\n",
    "    'c': (jnp.array([2 * jnp.pi]), jnp.array([3 * jnp.pi]))\n",
    "}\n",
    "\n",
    "# Apply jnp.cos to each element in the pytree\n",
    "cos_pytree = jax.tree.map(jnp.cos, pytree)\n",
    "cos_pytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76182c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd68894c",
   "metadata": {},
   "source": [
    "## JaxTyping + BearType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7dc6fe",
   "metadata": {},
   "source": [
    "This is not strictly JAX, but I think it's worth showing.\n",
    "`jaxtyping` offers integrations with run-time type checkers.\n",
    "Normally runtime type checking is slow, but with JIT, it can be fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d5af6",
   "metadata": {},
   "source": [
    "We are going to do this very explicitly, but there are faster tools. See [`install_import_hook`](https://docs.kidger.site/jaxtyping/api/runtime-type-checking/#jaxtyping.install_import_hook) to apply type-checking to an entire module, or the [IPython extension](https://docs.kidger.site/jaxtyping/api/runtime-type-checking/#ipython-extension) to do this in notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96061c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import jaxtyped  # explicit\n",
    "from beartype import beartype as typechecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff79047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@jaxtyped(typechecker=typechecker)  # explicit\n",
    "def checked_convolve(x: Float[Array, \"N\"], w: Float[Array, \"3\"]) -> Float[Array, \"N-2\"]:\n",
    "  return jnp.array([jnp.dot(x[i-1:i+2], w)\n",
    "                    for i in range(1, len(x)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "787f8cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type-check error whilst checking the parameters of __main__.checked_convolve.\n",
      "The problem arose whilst typechecking parameter 'x'.\n",
      "Actual value: i64[5]\n",
      "Expected type: <class 'Float[Array, 'N']'>.\n",
      "----------------------\n",
      "Called with parameters: {'x': i64[5], 'w': f64[3]}\n",
      "Parameter annotations: (x: Float[Array, 'N'], w: Float[Array, '3']) -> Any.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    checked_convolve(jnp.array([1, 2, 3, 4, 5]), jnp.array([2., 3, 4]))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "670cd786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([20., 29., 38.], dtype=float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_convolve(jnp.array([1., 2, 3, 4, 5]), jnp.array([2., 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "366f9e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.47 Î¼s Â± 26 ns per loop (mean Â± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit checked_convolve(x, w).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eaa47a",
   "metadata": {},
   "source": [
    "Runtime type checking with (almost) no performance penalty? ðŸ˜±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67da1d4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Warning: this can incur a large pre-compilation penalty. Check speeds. Runtime type checking is easy to turn off.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2686d0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6bac276",
   "metadata": {},
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81332dd1",
   "metadata": {},
   "source": [
    "1. `jax.numpy`\n",
    "2. vectorization\n",
    "3. `jit`\n",
    "4. differentiation\n",
    "5. PyTrees\n",
    "6. Runtime type-checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5e97a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flatiron-presentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
